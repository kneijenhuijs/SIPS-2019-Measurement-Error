@article{Button2015,
abstract = {BACKGROUND The Beck Depression Inventory, 2nd edition (BDI-II) is widely used in research on depression. However, the minimal clinically important difference (MCID) is unknown. MCID can be estimated in several ways. Here we take a patient-centred approach, anchoring the change on the BDI-II to the patient's global report of improvement. METHOD We used data collected (n = 1039) from three randomized controlled trials for the management of depression. Improvement on a 'global rating of change' question was compared with changes in BDI-II scores using general linear modelling to explore baseline dependency, assessing whether MCID is best measured in absolute terms (i.e. difference) or as percent reduction in scores from baseline (i.e. ratio), and receiver operator characteristics (ROC) to estimate MCID according to the optimal threshold above which individuals report feeling 'better'. RESULTS Improvement in BDI-II scores associated with reporting feeling 'better' depended on initial depression severity, and statistical modelling indicated that MCID is best measured on a ratio scale as a percentage reduction of score. We estimated a MCID of a 17.5{\%} reduction in scores from baseline from ROC analyses. The corresponding estimate for individuals with longer duration depression who had not responded to antidepressants was higher at 32{\%}. CONCLUSIONS MCID on the BDI-II is dependent on baseline severity, is best measured on a ratio scale, and the MCID for treatment-resistant depression is larger than that for more typical depression. This has important implications for clinical trials and practice.},
author = {Button, K S and Kounali, D and Thomas, L and Wiles, N J and Peters, T J and Welton, N J and Ades, A E and Lewis, G},
doi = {10.1017/S0033291715001270},
file = {:home/kneijenhuijs/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Button et al. - 2015 - Minimal clinically important difference on the Beck Depression Inventory--II according to the patient's perspecti.pdf:pdf},
issn = {1469-8978},
journal = {Psychological medicine},
keywords = {2nd edition (BDI-II),Beck Depression Inventory,depression,minimal clinically important difference,outcome assessment,primary care},
month = {nov},
number = {15},
pages = {3269--79},
pmid = {26165748},
publisher = {Cambridge University Press},
title = {{Minimal clinically important difference on the Beck Depression Inventory--II according to the patient's perspective.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26165748 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4611356},
volume = {45},
year = {2015}
}
@article{Button2015a,
abstract = {{\textless}div class="abstract" data-abstract-type="normal"{\textgreater}
                {\textless}sec id='sec{\_}a1'{\textgreater}
                   {\textless}span class="bold"{\textgreater}Background{\textless}/span{\textgreater}
                   {\textless}p{\textgreater}The Beck Depression Inventory, 2nd edition (BDI-II) is widely used in research on depression. However, the minimal clinically important difference (MCID) is unknown. MCID can be estimated in several ways. Here we take a patient-centred approach, anchoring the change on the BDI-II to the patient's global report of improvement.{\textless}/p{\textgreater}
                {\textless}/sec{\textgreater}
                {\textless}sec secType='methods' id='sec{\_}a2'{\textgreater}
                   {\textless}span class="bold"{\textgreater}Method{\textless}/span{\textgreater}
                   {\textless}p{\textgreater}We used data collected ({\textless}span class='italic'{\textgreater}n{\textless}/span{\textgreater} = 1039) from three randomized controlled trials for the management of depression. Improvement on a ‘global rating of change' question was compared with changes in BDI-II scores using general linear modelling to explore baseline dependency, assessing whether MCID is best measured in absolute terms (i.e. difference) or as percent reduction in scores from baseline (i.e. ratio), and receiver operator characteristics (ROC) to estimate MCID according to the optimal threshold above which individuals report feeling ‘better'.{\textless}/p{\textgreater}
                {\textless}/sec{\textgreater}
                {\textless}sec secType='results' id='sec{\_}a3'{\textgreater}
                   {\textless}span class="bold"{\textgreater}Results{\textless}/span{\textgreater}
                   {\textless}p{\textgreater}Improvement in BDI-II scores associated with reporting feeling ‘better' depended on initial depression severity, and statistical modelling indicated that MCID is best measured on a ratio scale as a percentage reduction of score. We estimated a MCID of a 17.5{\%} reduction in scores from baseline from ROC analyses. The corresponding estimate for individuals with longer duration depression who had not responded to antidepressants was higher at 32{\%}.{\textless}/p{\textgreater}
                {\textless}/sec{\textgreater}
                {\textless}sec secType='conclusion' id='sec{\_}a4'{\textgreater}
                   {\textless}span class="bold"{\textgreater}Conclusions{\textless}/span{\textgreater}
                   {\textless}p{\textgreater}MCID on the BDI-II is dependent on baseline severity, is best measured on a ratio scale, and the MCID for treatment-resistant depression is larger than that for more typical depression. This has important implications for clinical trials and practice.{\textless}/p{\textgreater}
                {\textless}/sec{\textgreater}
             {\textless}/div{\textgreater}},
author = {Button, K. S. and Kounali, D. and Thomas, L. and Wiles, N. J. and Peters, T. J. and Welton, N. J. and Ades, A. E. and Lewis, G.},
doi = {10.1017/S0033291715001270},
issn = {0033-2917},
journal = {Psychological Medicine},
keywords = {2nd edition (BDI-II),Beck Depression Inventory,depression,minimal clinically important difference,outcome assessment,primary care},
month = {nov},
number = {15},
pages = {3269--3279},
publisher = {Cambridge University Press},
title = {{Minimal clinically important difference on the Beck Depression Inventory - II according to the patient's perspective}},
url = {https://www.cambridge.org/core/product/identifier/S0033291715001270/type/journal{\_}article},
volume = {45},
year = {2015}
}
@article{Mokkink2010a,
abstract = {OBJECTIVE
Lack of consensus on taxonomy, terminology, and definitions has led to confusion about which measurement properties are relevant and which concepts they represent. The aim was to clarify and standardize terminology and definitions of measurement properties by reaching consensus among a group of experts and to develop a taxonomy of measurement properties relevant for evaluating health instruments. 

STUDY DESIGN AND SETTING
An international Delphi study with four written rounds was performed. Participating experts had a background in epidemiology, statistics, psychology, and clinical medicine. The panel was asked to rate their (dis)agreement about proposals on a five-point scale. Consensus was considered to be reached when at least 67{\%} of the panel agreed. 

RESULTS
Of 91 invited experts, 57 agreed to participate and 43 actually participated. Consensus was reached on positions of measurement properties in the taxonomy (68–84{\%}), terminology (74–88{\%}, except for structural validity [56{\%}]), and definitions of measurement properties (68–88{\%}). The panel extensively discussed the positions of internal consistency and responsiveness in the taxonomy, the terms “reliability” and “structural validity,” and the definitions of internal consistency and reliability. 

CONCLUSIONS
Consensus on taxonomy, terminology, and definitions of measurement properties was reached. Hopefully, this will lead to a more uniform use of terms and definitions in the literature on measurement properties.},
author = {Mokkink, Lidwine B. and Terwee, Caroline B. and Patrick, Donald L. and Alonso, Jordi and Stratford, Paul W. and Knol, Dirk L. and Bouter, Lex M. and de Vet, Henrica C.W.},
doi = {10.1016/J.JCLINEPI.2010.02.006},
issn = {0895-4356},
journal = {Journal of Clinical Epidemiology},
month = {jul},
number = {7},
pages = {737--745},
publisher = {Pergamon},
title = {{The COSMIN study reached international consensus on taxonomy, terminology, and definitions of measurement properties for health-related patient-reported outcomes}},
url = {https://www.sciencedirect.com/science/article/pii/S0895435610000909},
volume = {63},
year = {2010}
}
@article{Myles2007,
author = {Myles, P.S. and Cui, J.},
doi = {10.1093/bja/aem214},
issn = {00070912},
journal = {British Journal of Anaesthesia},
month = {sep},
number = {3},
pages = {309--311},
publisher = {Narnia},
title = {{I. Using the Bland–Altman method to measure agreement with repeated measures}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0007091217347153},
volume = {99},
year = {2007}
}
@article{Posternak2001,
author = {Posternak, MA and Miller, I},
journal = {Journal of affective disorders},
number = {2-3},
pages = {139--146},
title = {{Untreated short-term course of major depression: a meta-analysis of outcomes from studies using wait-list control groups}},
url = {https://www.sciencedirect.com/science/article/pii/S0165032700003049},
volume = {66},
year = {2001}
}
@article{Wang2013,
author = {Wang, Yuan-Pang and Gorenstein, Clarice},
journal = {Brazilian Journal of Psychiatry},
number = {4},
pages = {416--431},
title = {{Psychometric properties of the Beck Depression Inventory-II: a comprehensive review}},
url = {http://www.scielo.br/scielo.php?pid=S1516-44462013000400416{\&}script=sci{\_}arttext},
volume = {35},
year = {2013}
}
@article{Parsons2019,
author = {Parsons, S. and Kruijt, AW. and Fox, Elaine},
journal = {preprint},
number = {},
pages = {1-44},
title = {{Psychological Science needs a standard practice of reporting the reliability of cognitive behavioural measurements}},
url = {https://psyarxiv.com/6ka9z},
volume = {},
year = {2019}
}
@article{hedge_reliability_2018,
	title = {The reliability paradox: Why robust cognitive tasks do not produce reliable individual differences},
	volume = {50},
	issn = {1554-3528},
	url = {http://link.springer.com/10.3758/s13428-017-0935-1},
	doi = {10.3758/s13428-017-0935-1},
	shorttitle = {The reliability paradox},
	pages = {1166--1186},
	number = {3},
	journaltitle = {Behavior Research Methods},
	author = {Hedge, Craig and Powell, Georgina and Sumner, Petroc},
	urldate = {2019-01-16},
	date = {2018-06},
	langid = {english},
	file = {Hedge et al. - 2018 - The reliability paradox Why robust cognitive task.pdf:C\:\\Users\\parsonss\\Zotero\\storage\\EP44ZT4Z\\Hedge et al. - 2018 - The reliability paradox Why robust cognitive task.pdf:application/pdf}
}
@article{rouder_why_2019,
	title = {Why Most Studies of Individual Differences With Inhibition Tasks Are Bound To Fail},
	url = {https://osf.io/3cjr5},
	doi = {10.31234/osf.io/3cjr5},
	abstract = {Establishing correlations among common inhibition tasks such as Stroop or ﬂanker tasks has been proven quite diﬃcult despite many attempts. It remains unknown whether this diﬃculty occurs because inhibition is a disparate set of phenomena or whether the analytical techiques to uncover a uniﬁed inhibition phenomenon fail in real-world contexts. In this paper, we explore the ﬁeld-wide inability to assess whether inhibition is uniﬁed or disparate. We do so by showing that ordinary methods of correlating performance including those with latent variable models are doomed to fail because of trial noise (or, as it is sometimes called, measurement error). We then develop hierarchical models that account for variation across trials, variation across individuals, and covariation across individuals and tasks. These hierarchical models also fail to uncover correlations in typical designs for the same reasons. While we can charaterize the degree of trial noise, we cannot recover correlations in typical designs that enroll hundreds of people. We discuss possible improvements to study designs to help uncovering correlations, though we are not sure how feasible they are.},
	author = {Rouder, Jeffrey and Kumar, Aakriti and Haaf, Julia M},
	urldate = {2019-04-03},
	date = {2019},
	langid = {english},
	note = {00000},
	file = {Rouder et al. - Why Most Studies of Individual Differences With In.pdf:C\:\\Users\\parsonss\\Zotero\\storage\\TRV648PW\\Rouder et al. - Why Most Studies of Individual Differences With In.pdf:application/pdf}
}
@article{Davis-Stober2018,
abstract = {Sample means comparisons are a fundamental and ubiquitous approach to interpreting experimental psychological data. Yet, we argue that the sample and effect sizes in published psychological research are frequently so small that sample means are insufficiently accurate to determine whether treatment effects have occurred. Generally, an estimator should be more accurate than any benchmark that systematically ignores information about the relations among experimental conditions. We consider two such benchmark estimators: one that randomizes the relations among conditions and another that always assumes no treatment effects. We show conditions under which these benchmark estimators estimate the true parameters more accurately than sample means. This perverse situation can occur even when effects are statistically significant at traditional levels. Our argument motivates the need for regularized estimates, such as those used in lasso, ridge, and hierarchical Bayes techniques.},
author = {Davis-Stober, Clintin P. and Dana, Jason and Rouder, Jeffrey N.},
doi = {10.1371/journal.pone.0207239},
editor = {Hutson, Alan D},
issn = {1932-6203},
journal = {PLOS ONE},
month = {nov},
number = {11},
pages = {e0207239},
publisher = {Public Library of Science},
title = {{Estimation accuracy in the psychological sciences}},
url = {http://dx.plos.org/10.1371/journal.pone.0207239},
volume = {13},
year = {2018}
}
